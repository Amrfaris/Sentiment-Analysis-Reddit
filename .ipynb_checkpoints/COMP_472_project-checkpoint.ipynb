{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "#### this class is purely for organisation and ease of access, instead of messy nested array access , we just create a posts object with attributes ( the post itself, its emotion, its sentiment )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Posts : \n",
    "    def __init__(self, post, emotion, sentiment):\n",
    "        self.post = post\n",
    "        self.emotion = emotion\n",
    "        self.sentiment = sentiment\n",
    "        \n",
    "    def print(self):\n",
    "        print(f\"post: {self.post} emotion: {self.emotion} sentiment: {self.sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "posts = []\n",
    "\n",
    "# the file given to us is a gzip which has a json inside it, so we need to unzip first and then load the json file \n",
    "\n",
    "with gzip.open('goemotions.json.gz', 'r') as f: # unzipping\n",
    "    data = json.loads(f.read(), encoding=\"utf-8\") # loading json\n",
    "    for line in data:\n",
    "        posts.append(Posts(line[0],line[1],line[2])) #creating the object and appending to the list \n",
    "        \n",
    "# basically posts is a list of objects where each object has its info as attributes ( see above )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Plotting Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emotions = list(set([x.emotion for x in posts]))\n",
    "all_sentiments = list(set([x.sentiment for x in posts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_emotions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m emotion_count \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emotion_loop \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_emotions\u001b[49m:\n\u001b[0;32m      6\u001b[0m     emotion_count[emotion_loop]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m posts \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39memotion \u001b[38;5;241m==\u001b[39m emotion_loop])\n\u001b[0;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_emotions' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emotion_count = {}\n",
    "\n",
    "for emotion_loop in all_emotions:\n",
    "    emotion_count[emotion_loop]= len([x for x in posts if x.emotion == emotion_loop])\n",
    "        \n",
    "labels = []\n",
    "sizes = []\n",
    "\n",
    "for x, y in emotion_count.items():\n",
    "    labels.append(x)\n",
    "    sizes.append(y)\n",
    "\n",
    "patches, texts = plt.pie(sizes,startangle=90)\n",
    "plt.legend(patches, labels, loc='center left', bbox_to_anchor=(-0.35, .5), fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_count = {}\n",
    "\n",
    "for sent_loop in all_sentiments:\n",
    "    sent_count[sent_loop]= len([x for x in posts if x.sentiment == sent_loop])\n",
    "\n",
    "labels = []\n",
    "sizes = []\n",
    "\n",
    "for x, y in sent_count.items():\n",
    "    labels.append(x)\n",
    "    sizes.append(y)\n",
    "\n",
    "plt.pie(sizes, labels=labels)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Proccessing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#getting frequency of each word \n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(x.post for x in posts)\n",
    "#print(\"Vocabulary: \", vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The number of tokens is 30449\n"
     ]
    }
   ],
   "source": [
    "print(f\" The number of tokens is {len(vectorizer.vocabulary_)}\") # no. of distinct words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train/Test split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "training_set, testing_set = train_test_split(posts, test_size=0.2, random_state = 42) \n",
    "# what this does is randomly splitting the posts list of objects into 80/20 train/test respectively,  \n",
    "\n",
    "train_x = np.array([x.post for x in training_set]) # now we need to seperate our x's and y's for both train and split tests\n",
    "train_emotion_y = np.array([x.emotion for x in training_set]) # this is the y you feed to your model\n",
    "train_sentiment_y = [x.sentiment for x in training_set] # same thing ^\n",
    "\n",
    "test_x = [x.post for x in testing_set]\n",
    "test_emotion_y = [x.emotion for x in testing_set]\n",
    "test_sentiment_y = [x.sentiment for x in testing_set]\n",
    "\n",
    "\n",
    "vectorized_train_x = vectorizer.fit_transform(train_x) # this is the x you feed to your model \n",
    "vectorized_test_x = vectorizer.transform(test_x) # dw about this for now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Train and test classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Base-MNB - Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for emotions = ['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'admiration']\n",
      "score of model 1 on emotions =  0.3835991153532767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_emotion = MultinomialNB()\n",
    "\n",
    "mnb_fit_emotion = mnb_emotion.fit(vectorized_train_x,train_emotion_y)\n",
    "\n",
    "y_pred_mnb_emotion = mnb_fit_emotion.predict(vectorized_test_x)\n",
    "\n",
    "\n",
    "print(\"Predictions for emotions =\", y_pred_mnb_emotion)\n",
    "print(\"score of model 1 on emotions = \", mnb_fit_emotion.score(vectorized_test_x,test_emotion_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Base-MNB - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for sentiments = ['positive' 'ambiguous' 'neutral' ... 'neutral' 'neutral' 'positive']\n",
      "score of model 2 on sentiment =  0.5469386567337912\n"
     ]
    }
   ],
   "source": [
    "mnb_sentiment = MultinomialNB()\n",
    "mnb_fit_sentiment = mnb_sentiment.fit(vectorized_train_x,train_sentiment_y)\n",
    "\n",
    "y_pred_mnb_sentiment = mnb_fit_sentiment.predict(vectorized_test_x)\n",
    "print(\"\\nPredictions for sentiments =\", y_pred_mnb_sentiment)\n",
    "print(\"score of model 2 on sentiment = \", mnb_fit_sentiment.score(vectorized_test_x,test_sentiment_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Base-DT - EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for emotions with decision tree = ['optimism' 'confusion' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "\n",
      "score of model 1 on emotions with decision tree =  0.35959143289489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_emotion = DecisionTreeClassifier()\n",
    "dt_emotion_fit = dt_emotion.fit(vectorized_train_x,train_emotion_y)\n",
    "\n",
    "y_pred_dt_emotion =  dt_emotion_fit.predict(vectorized_test_x)\n",
    "dt_emotion_score = dt_emotion_fit.score(vectorized_test_x,test_emotion_y)\n",
    "\n",
    "print(\"Predictions for emotions with decision tree =\", y_pred_dt_emotion)\n",
    "print(\"\\nscore of model 1 on emotions with decision tree = \",dt_emotion_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Base-DT - SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for sentiments with decision tree = ['positive' 'ambiguous' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "score of model 2 on sentiment with decision tree =  0.5432429286462577\n"
     ]
    }
   ],
   "source": [
    "dt_sentiment = DecisionTreeClassifier()\n",
    "dt_sentiment_fit = dt_sentiment.fit(vectorized_train_x,train_sentiment_y)\n",
    "y_pred_dt_sentiment = dt_sentiment_fit.predict(vectorized_test_x)\n",
    "dt_sentiment_score = dt_sentiment_fit.score(vectorized_test_x,test_sentiment_y)\n",
    "print(\"\\nPredictions for sentiments with decision tree =\", y_pred_dt_sentiment)\n",
    "print(\"score of model 2 on sentiment with decision tree = \", dt_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Base-MLP - EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376091258293563"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.neural_network import MLPClassifier\n",
    "mlp_emotion = MLPClassifier(random_state=2, max_iter=1).fit(vectorized_train_x, train_emotion_y)\n",
    "y_pred_mlp_emotion = mlp_emotion.predict(vectorized_test_x)\n",
    "\n",
    "mlp_emotion_score = mlp_emotion.score(vectorized_test_x,test_emotion_y)\n",
    "mlp_emotion_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Base-MLP - SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653008962868118"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_sentiment = MLPClassifier(random_state=2, max_iter=1).fit(vectorized_train_x, train_sentiment_y)\n",
    "y_pred_mlp_sentiment = mlp_sentiment.predict(vectorized_test_x)\n",
    "mlp_sentiment_score = mlp_sentiment.score(vectorized_test_x,test_sentiment_y)\n",
    "mlp_sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Top - MNB - EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"alpha\": [0.5, 0, 1, 2]}\n",
    "TOP_mnb_emotion = MultinomialNB()\n",
    "grid_emotion_mnb = GridSearchCV(TOP_mnb_emotion, param_grid, n_jobs = -1,verbose=2)\n",
    "\n",
    "grid_emotion_mnb.fit(vectorized_train_x,train_emotion_y)\n",
    "print(grid_emotion_mnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3908450704225352"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_TOPmnb_emotion = grid_emotion_mnb.predict(vectorized_test_x)\n",
    "grid_emotion_mnb.score(vectorized_test_x,test_emotion_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Top - MNB - SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "TOP_mnb_sentiment = MultinomialNB()\n",
    "\n",
    "grid_sentiment_mnb = GridSearchCV(TOP_mnb_sentiment, param_grid,n_jobs = -1, verbose=2)\n",
    "grid_sentiment_mnb.fit(vectorized_train_x,train_sentiment_y)\n",
    "\n",
    "print(grid_sentiment_mnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5469386567337912"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_TOPmnb_sentiment = grid_sentiment_mnb.predict(vectorized_test_x)\n",
    "\n",
    "grid_sentiment_mnb.score(vectorized_test_x,test_sentiment_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Top-DT - EMOTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_DT = {\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":[5,10] , \"min_samples_split\":[5,10,20]}\n",
    "dt_emotion_top = DecisionTreeClassifier()\n",
    "grid_dt_emotion = GridSearchCV(dt_emotion_top, param_grid_DT, n_jobs = -1 , verbose=2)\n",
    "\n",
    "grid_dt_emotion.fit(vectorized_train_x,train_emotion_y)\n",
    "grid_dt_emotion.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39046676754743337\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt_emotion.score(vectorized_test_x,test_emotion_y))\n",
    "y_pred_TOPdt_emotion = grid_dt_emotion.predict(vectorized_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Top-DT - SENTIMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_sentiment_top = DecisionTreeClassifier()\n",
    "grid_dt_sentiment = GridSearchCV(dt_sentiment_top, param_grid_DT, n_jobs = -1,verbose=2)\n",
    "grid_dt_sentiment.fit(vectorized_train_x,train_sentiment_y)\n",
    "\n",
    "grid_dt_sentiment.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4248341287393784\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt_sentiment.score(vectorized_test_x,test_sentiment_y))\n",
    "y_pred_TOPdt_sentiment = grid_dt_sentiment.predict(vectorized_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 TOP - MLP - EMOTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(max_iter=1, random_state=2), n_jobs=-1,\n",
       "             param_grid={'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
       "                         'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_mlp= {'activation':[\"logistic\",\"tanh\",\"relu\",\"identity\"],\"hidden_layer_sizes\":[(30,50),(10,10,10)],\"solver\":['sgd','adam']}\n",
    "mlp_emotion_top =  MLPClassifier(random_state=2, max_iter=1)\n",
    "grid_mlp_emotion = GridSearchCV(mlp_emotion_top, param_grid_mlp, n_jobs = -1,verbose=2)\n",
    "\n",
    "grid_mlp_emotion.fit(vectorized_train_x,train_emotion_y)\n",
    "\n",
    "grid_mlp_emotion.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4318181818181818\n"
     ]
    }
   ],
   "source": [
    "print(grid_mlp_emotion.score(vectorized_test_x,test_emotion_y))\n",
    "y_pred_TOPmlp_emotion = grid_mlp_emotion.predict(vectorized_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 TOP - MLP - SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sentiment_top =  MLPClassifier(random_state=2, max_iter=1)\n",
    "grid_mlp_sentiment  = GridSearchCV(mlp_sentiment_top, param_grid_mlp,n_jobs = -1, verbose=2)\n",
    "grid_mlp_sentiment.fit(vectorized_train_x,train_sentiment_y)\n",
    "\n",
    "grid_mlp_sentiment.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mlp_sentiment.score(vectorized_test_x,test_sentiment_y)\n",
    "y_pred_TOPmlp_sentiment = grid_mlp_sentiment.predict(vectorized_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(conf,clas, file, title): # expects conf. matrix, classification report, file path and title as \n",
    "    with open(file, 'a') as f: # \"a\" appends text to file\n",
    "        f.write(f\"{title}\\n\\nConfusion Matrix: \\n{conf}\\n\\nCLassification Report: \\n{clas}\\n\\n\\n\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "open(\"performance.txt\", \"w\").close() #clears file (ensures file is empty when before it starts)\n",
    "\n",
    "mnb_matrix_emotion = confusion_matrix(test_emotion_y,y_pred_mnb_emotion)\n",
    "mnb_clas_emotion = classification_report(test_emotion_y, y_pred_mnb_emotion)\n",
    "\n",
    "write_to_file(mnb_matrix_emotion,mnb_clas_emotion, 'performance.txt',' BASE MNB - EMOTION')\n",
    "\n",
    "mnb_matrix_sentiment = confusion_matrix(test_sentiment_y,y_pred_mnb_sentiment)\n",
    "mnb_clas_sentiment = classification_report(test_sentiment_y, y_pred_mnb_sentiment)\n",
    "\n",
    "write_to_file(mnb_matrix_sentiment,mnb_clas_sentiment, 'performance.txt',' BASE MNB - SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_matrix_emotion = confusion_matrix(test_emotion_y,y_pred_dt_emotion)\n",
    "dt_clas_emotion = classification_report(test_emotion_y, y_pred_dt_emotion)\n",
    "\n",
    "write_to_file(dt_matrix_emotion,dt_clas_emotion, 'performance.txt',' BASE DT - EMOTION')\n",
    "\n",
    "dt_matrix_sentiment = confusion_matrix(test_sentiment_y,y_pred_dt_sentiment)\n",
    "dt_clas_sent = classification_report(test_sentiment_y, y_pred_dt_sentiment)\n",
    "\n",
    "write_to_file(dt_matrix_sentiment,dt_clas_sent, 'performance.txt',' BASE DT - SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_matrix_emotion = confusion_matrix(test_emotion_y,y_pred_mlp_emotion)\n",
    "mlp_clas_emotion = classification_report(test_emotion_y, y_pred_mlp_emotion)\n",
    "\n",
    "write_to_file(mlp_matrix_emotion,mlp_clas_emotion, 'performance.txt',' BASE MLP - EMOTION')\n",
    "\n",
    "mlp_matrix_sentiment = confusion_matrix(test_sentiment_y,y_pred_mlp_sentiment)\n",
    "mlp_clas_sentiment = classification_report(test_sentiment_y, y_pred_mlp_sentiment)\n",
    "\n",
    "write_to_file(mlp_matrix_sentiment,mlp_clas_sentiment, 'performance.txt',' BASE MLP - SENTIMENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP MNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TOPmnb_matrix_emotion = confusion_matrix(test_emotion_y, y_pred_TOPmnb_emotion)\n",
    "TOPmnb_clas_emotion = classification_report(test_emotion_y, y_pred_TOPmnb_emotion)\n",
    "\n",
    "write_to_file(TOPmnb_matrix_emotion,TOPmnb_clas_emotion, 'performance.txt',' TOP MNB - EMOTION')\n",
    "\n",
    "TOPmnb_matrix_sentiment = confusion_matrix(test_sentiment_y, y_pred_TOPmnb_sentiment)\n",
    "TOPmnb_clas_sent = classification_report(test_sentiment_y, y_pred_TOPmnb_sentiment)\n",
    "\n",
    "write_to_file(TOPmnb_matrix_sentiment,TOPmnb_clas_sent, 'performance.txt',' TOP MNB - SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TOPdt_matrix_emotion = confusion_matrix(test_emotion_y, y_pred_TOPdt_emotion)\n",
    "TOPdt_clas_emotion = classification_report(test_emotion_y, y_pred_TOPdt_emotion)\n",
    "\n",
    "write_to_file(TOPdt_matrix_emotion,TOPdt_clas_emotion, 'performance.txt',' TOP DT - EMOTION')\n",
    "\n",
    "TOPdt_matrix_sentiment = confusion_matrix(test_sentiment_y, y_pred_TOPdt_sentiment)\n",
    "TOPdt_clas_sentiment = classification_report(test_sentiment_y, y_pred_TOPdt_sentiment)\n",
    "\n",
    "write_to_file(TOPdt_matrix_sentiment,TOPdt_clas_sentiment, 'performance.txt',' TOP DT - SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPmlp_matrix_emotion = confusion_matrix(test_emotion_y, y_pred_TOPmlp_emotion)\n",
    "TOPmlp_clas_emotion = classification_report(test_emotion_y, y_pred_TOPmlp_emotion)\n",
    "\n",
    "write_to_file(TOPmlp_matrix_emotion,TOPmlp_clas_emotion, 'performance.txt',' TOP MLP - EMOTION')\n",
    "\n",
    "\n",
    "# TOPmlp_matrix_sentiment = confusion_matrix(test_sentiment_y, y_pred_TOPmlp_sentiment)\n",
    "# TOPmlp_clas_sentiment = classification_report(test_sentiment_y, y_pred_TOPmlp_sentiment)\n",
    "\n",
    "#write_to_file(TOPmlp_matrix_sentiment,TOPmlp_clas_sentiment, 'performance.txt',' TOP MLP - SENTIMENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Remove Stopwords and redo 2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e27aaff05bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcoun_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoun_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mposts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#print(\"Vocabulary: \", coun_vect.vocabulary_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'posts' is not defined"
     ]
    }
   ],
   "source": [
    "# Processing Data with removal of stop words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "coun_vect = CountVectorizer(stop_words='english')\n",
    "X_stopW = coun_vect.fit_transform(x.post for x in posts)\n",
    "#print(\"Vocabulary: \", coun_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The number of tokens is 30148\n"
     ]
    }
   ],
   "source": [
    "print(f\" The number of tokens is {len(coun_vect.vocabulary_)}\") # it was 30449 before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making new training set and testing set\n",
    "\n",
    "coun_vect_train_x = coun_vect.fit_transform(train_x) \n",
    "coun_vect_test_x = coun_vect.transform(test_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-MNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for emotions = ['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'optimism']\n",
      "\n",
      "Predictions for sentiments = ['positive' 'neutral' 'neutral' ... 'neutral' 'neutral' 'positive']\n",
      "\n",
      "score of model 1 on emotions =  0.3884297520661157\n",
      "score of model 2 on sentiment =  0.5415551158188803\n"
     ]
    }
   ],
   "source": [
    "mnb_emotion_stopW = MultinomialNB()\n",
    "mnb_sentiment_stopW = MultinomialNB()\n",
    "mnb_fit_emotion_stopW = mnb_emotion_stopW.fit(coun_vect_train_x,train_emotion_y)\n",
    "mnb_fit_sentiment_stopW = mnb_sentiment_stopW.fit(coun_vect_train_x,train_sentiment_y)\n",
    "\n",
    "y_pred_mnb_emotion_stopW = mnb_fit_emotion_stopW.predict(coun_vect_test_x)\n",
    "y_pred_mnb_sentiment_stopW = mnb_fit_sentiment_stopW.predict(coun_vect_test_x)\n",
    "\n",
    "print(\"Predictions for emotions =\", y_pred_mnb_emotion_stopW)\n",
    "print(\"\\nPredictions for sentiments =\", y_pred_mnb_sentiment_stopW)\n",
    "\n",
    "print(\"\\nscore of model 1 on emotions = \", mnb_fit_emotion_stopW.score(coun_vect_test_x,test_emotion_y))\n",
    "print(\"score of model 2 on sentiment = \", mnb_fit_sentiment_stopW.score(coun_vect_test_x,test_sentiment_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for emotions with decision tree = ['optimism' 'confusion' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "\n",
      "Predictions for sentiments with decision tree = ['positive' 'ambiguous' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "\n",
      "score of model 1 on emotions with decision tree =  0.3612501455011058\n",
      "score of model 2 on sentiment with decision tree =  0.543679431963683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_emotion_stopW = DecisionTreeClassifier()\n",
    "dt_sentiment_stopW = DecisionTreeClassifier()\n",
    "dt_emotion_fit_stopW = dt_emotion_stopW.fit(coun_vect_train_x,train_emotion_y)\n",
    "dt_sentiment_fit_stopW = dt_sentiment_stopW.fit(coun_vect_train_x,train_sentiment_y)\n",
    "\n",
    "y_pred_dt_emotion_stopW =  dt_emotion_fit_stopW.predict(coun_vect_test_x)\n",
    "y_pred_dt_sentiment_stopW = dt_sentiment_fit_stopW.predict(coun_vect_test_x)\n",
    "\n",
    "dt_emotion_score_stopW = dt_emotion_fit_stopW.score(coun_vect_test_x,test_emotion_y)\n",
    "dt_sentiment_score_stopW = dt_sentiment_fit_stopW.score(coun_vect_test_x,test_sentiment_y)\n",
    "\n",
    "print(\"Predictions for emotions with decision tree =\", y_pred_dt_emotion_stopW)\n",
    "print(\"\\nPredictions for sentiments with decision tree =\", y_pred_dt_sentiment_stopW)\n",
    "print(\"\\nscore of model 1 on emotions with decision tree = \",dt_emotion_score_stopW)\n",
    "print(\"score of model 2 on sentiment with decision tree = \", dt_sentiment_score_stopW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_emotion_stopW = MLPClassifier(random_state=2, max_iter=1).fit(coun_vect_train_x, train_emotion_y)\n",
    "y_pred_mlp_emotion_stopW = mlp_emotion_stopW.predict(coun_vect_test_x)\n",
    "\n",
    "mlp_sentiment_stopW = MLPClassifier(random_state=2, max_iter=1).fit(coun_vect_train_x, train_sentiment_y)\n",
    "y_pred_mlp_sentiment_stopW = mlp_sentiment_stopW.predict(coun_vect_test_x)\n",
    "\n",
    "\n",
    "mlp_emotion_score_stopW = mlp_emotion_stopW.score(coun_vect_test_x,test_emotion_y)\n",
    "print(\"\\nScore for emotion with base-MLP =\", mlp_emotion_score)\n",
    "\n",
    "mlp_sentiment_score_stopW = mlp_sentiment_stopW.score(coun_vect_test_x,test_sentiment_y)\n",
    "print(\"\\nScore for sentiment with base-MLP =\", mlp_sentiment_score_stopW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [0.5, 0, 1, 2]}\n",
    "TOP_mnb_emotion_stopW = MultinomialNB()\n",
    "TOP_mnb_sentiment_stopW = MultinomialNB()\n",
    "grid_emotion_mnb_stopW = GridSearchCV(TOP_mnb_emotion_stopW, param_grid, verbose=2)\n",
    "grid_sentiment_mnb_stopW = GridSearchCV(TOP_mnb_sentiment_stopW, param_grid, verbose=2)\n",
    "\n",
    "grid_emotion_mnb_stopW.fit(coun_vect_train_x,train_emotion_y)\n",
    "grid_sentiment_mnb_stopW.fit(coun_vect_train_x,train_sentiment_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [0.5, 0, 1, 2]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [0.5, 0, 1, 2]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(), param_grid={'alpha': [0.5, 0, 1, 2]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ..........................................alpha=0.5; total time=   0.1s\n",
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time=   0.1s\n",
      "[CV] END ............................................alpha=0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=1; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n",
      "[CV] END ............................................alpha=2; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [0.5, 0, 1, 2]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [0.5, 0, 1, 2]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(), param_grid={'alpha': [0.5, 0, 1, 2]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for emotion with top-MNB = 0.393143987894308\n",
      "\n",
      "Score for sentiment with top-MNB = 0.5415551158188803\n"
     ]
    }
   ],
   "source": [
    "y_pred_TOPmnb_emotion_stopW = grid_emotion_mnb_stopW.predict(coun_vect_test_x)\n",
    "TOPmnb_emotion_labels_stopW = set(y_pred_TOPmnb_emotion_stopW)\n",
    "y_pred_TOPmnb_sentiment_stopW = grid_sentiment_mnb_stopW.predict(coun_vect_test_x)\n",
    "TOPmnb_sentiment_labels_stopW = set(y_pred_TOPmnb_sentiment_stopW)\n",
    "\n",
    "top_MNB_emotion_score_stopW = grid_emotion_mnb_stopW.score(coun_vect_test_x,test_emotion_y)\n",
    "print(\"\\nScore for emotion with top-MNB =\", top_MNB_emotion_score_stopW)\n",
    "top_MNB_sentiment_score_stopW = grid_sentiment_mnb_stopW.score(coun_vect_test_x,test_sentiment_y)\n",
    "print(\"\\nScore for sentiment with top-MNB =\", top_MNB_sentiment_score_stopW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_DT = {\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":[5,10] , \"min_samples_split\":[5,10,20]}\n",
    "dt_emotion_top_stopW = DecisionTreeClassifier()\n",
    "grid_dt_emotion_stopW = GridSearchCV(dt_emotion_top_stopW, param_grid_DT, n_jobs = -1 , verbose=2)\n",
    "\n",
    "grid_dt_emotion_stopW.fit(coun_vect_train_x,train_emotion_y)\n",
    "grid_dt_emotion_stopW.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for emotion with top-DT = 0.391136072634152\n"
     ]
    }
   ],
   "source": [
    "grid_dt_emotion_score_stopW= (grid_dt_emotion_stopW.score(coun_vect_test_x,test_emotion_y))\n",
    "y_pred_TOPdt_emotion_stopW = grid_dt_emotion_stopW.predict(coun_vect_test_x)\n",
    "\n",
    "print(\"\\nScore for emotion with top-DT =\", grid_dt_emotion_score_stopW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_sentiment_top_stopW = DecisionTreeClassifier()\n",
    "grid_dt_sentiment_stopW = GridSearchCV(dt_sentiment_top_stopW, param_grid_DT, n_jobs = -1,verbose=2)\n",
    "grid_dt_sentiment_stopW.fit(coun_vect_train_x,train_sentiment_y)\n",
    "\n",
    "grid_dt_sentiment_stopW.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for sentiment with top-DT = 0.425416133162612\n"
     ]
    }
   ],
   "source": [
    "grid_dt_sentiment_score_stopW= (grid_dt_sentiment_stopW.score(coun_vect_test_x,test_sentiment_y))\n",
    "y_pred_TOPdt_sentiment_stopW = grid_dt_sentiment_stopW.predict(coun_vect_test_x)\n",
    "print(\"\\nScore for sentiment with top-DT =\", grid_dt_sentiment_score_stopW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid_mlp= {'activation':[\"logistic\",\"tanh\",\"relu\",\"identity\"],\"hidden_layer_sizes\":[(30,50),(10,10,10)],\"solver\":['sgd','adam']}\n",
    "mlp_emotion_top_stopW =  MLPClassifier(random_state=2, max_iter=1)\n",
    "grid_mlp_emotion_stopW = GridSearchCV(mlp_emotion_top_stopW, param_grid_mlp, n_jobs = -1,verbose=2)\n",
    "\n",
    "grid_mlp_emotion_stopW.fit(coun_vect_train_x,train_emotion_y)\n",
    "\n",
    "grid_mlp_emotion_stopW.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mlp_emotion_score_stopW= (grid_mlp_emotion_stopW.score(coun_vect_train_x,test_emotion_y))\n",
    "y_pred_TOPmlp_emotion_stopW = grid_mlp_emotion_stopW.predict(vectorized_test_x)\n",
    "print(\"\\nScore for emotion with top-MLP =\", grid_mlp_emotion_score_stopW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sentiment_top_stopW =  MLPClassifier(random_state=2, max_iter=1)\n",
    "grid_mlp_sentiment_stopW  = GridSearchCV(mlp_sentiment_top_stopW, param_grid_mlp,n_jobs = -1, verbose=2)\n",
    "grid_mlp_sentiment_stopW.fit(coun_vect_train_x,train_sentiment_y)\n",
    "\n",
    "grid_mlp_sentiment_stopW.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mlp_sentiment_score_stopW = (grid_mlp_sentiment_stopW.score(coun_vect_test_x,test_sentiment_y))\n",
    "y_pred_TOPmlp_sentiment_stopW = grid_mlp_sentiment_stopW.predict(coun_vect_test_x)\n",
    "print(\"\\nScore for sentiment with top-MLP =\", grid_mlp_sentiment_score_stopW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
